---
title: "Fine-grained Hallucination Detection and Editing for Language Models"
collection: publications
permalink: /publication/fine-grained-hallucination-detection
excerpt: 'Large language models (LMs) are prone to generate diverse factually incorrect statements, which are widely called hallucinations. Current approaches predominantly focus on coarse-grained automatic hallucination detection or editing, overlooking nuanced error levels. In this paper, we propose a novel task—automatic fine-grained hallucination detection—and present a comprehensive taxonomy encompassing six hierarchically defined types of hallucination.'
date: 2024-01-01
venue: 'ArXiv'
paperurl: 'https://arxiv.org/pdf/2401.06855.pdf'
---
